{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning means fixing bad data in your data set.\n",
    "\n",
    "Bad data could be:\n",
    "\n",
    "Empty cells, Data in wrong format, Wrong data, Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty Cells : Empty cells can potentially give you a wrong result when you analyze data.\n",
    "\n",
    "# ==================================================================================================\n",
    "\n",
    "# 1. REMOVE ROWS\n",
    "import pandas as pd\n",
    "\n",
    "# Read CSV File\n",
    "# df = pd.read_csv('Data_Cleaning.csv')\n",
    "# print(df)\n",
    "\n",
    "# dropna() : Remove all rows with NULL values\n",
    "# Note: By default, the dropna() method returns a new DataFrame, and will not change the original.\n",
    "# new_df = df.dropna()\n",
    "# print(new_df)\n",
    "\n",
    "# Keep the original DataFrame\n",
    "# Note: Now, the dropna(inplace = True) will NOT return a new DataFrame, but it will remove all rows containing NULL values from the original DataFrame.\n",
    "# df.dropna(inplace=True)\n",
    "# print(df)\n",
    "\n",
    "# ==================================================================================================\n",
    "\n",
    "# 2. REPLACE EMPTY VALUES\n",
    "# Fill Empty Cells\n",
    "# Note: The fillna() method allows us to replace empty cells with a value\n",
    "# df.fillna(130, inplace=True)\n",
    "# print(df)\n",
    "\n",
    "# Replace Only For Specified Columns\n",
    "# Syntax 1: df[col].method(value, inplace=True)\n",
    "# df[\"Calories\"].fillna(130, inplace=True)\n",
    "\n",
    "# Syntax 2: df.method({col: value}, inplace=True)\n",
    "# df.fillna({\"Calories\": 130}, inplace=True)\n",
    "\n",
    "# Syntax 3: df[col] = df[col].method(value)\n",
    "# df['Calories'] = df['Calories'].fillna(130)\n",
    "\n",
    "# ==================================================================================================\n",
    "\n",
    "# REPLACE USING MEAN, MEDIAN, OR MODE\n",
    "# Pandas uses the mean() median() and mode() methods to calculate the respective values for a specified column:\n",
    "# Mean = the average value (the sum of all values divided by number of values).\n",
    "# x = df[\"Calories\"].mean()\n",
    "# Median = the value in the middle, after you have sorted all values ascending.\n",
    "# x = df[\"Calories\"].median()\n",
    "# Mode = the value that appears most frequently.\n",
    "# x = df[\"Calories\"].mode()[0]\n",
    "\n",
    "# df[\"Calories\"].fillna(x, inplace=True)\n",
    "\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA OF WRONG FORMAT : Data of wrong format can make it difficult, or even impossible, to analyze data.\n",
    "\n",
    "# df = pd.read_csv(\"Data_Cleaning.csv\")\n",
    "# print(df)\n",
    "# To fix it, you have two options: remove the rows, or convert all cells in the columns into the same format.\n",
    "\n",
    "# ==================================================================================================\n",
    "\n",
    "# 1. CONVERT INTO A CORRECT FORMAT\n",
    "# Convert the 'Date' column to datetime, errors='coerce' will turn invalid dates to NaT (missing dates)\n",
    "# df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "# Print the dataframe to see the changes\n",
    "# print(df.to_string())\n",
    "\n",
    "# ==================================================================================================\n",
    "\n",
    "# OPTIONALLY, YOU CAN DROP ROWS WITH MISSING DATES OR FILL THEM\n",
    "# Drop rows where 'Date' is NaT\n",
    "# df_cleaned = df.dropna(subset=[\"Date\"])\n",
    "# print(df_cleaned.to_string())\n",
    "\n",
    "# ==================================================================================================\n",
    "\n",
    "# OR FILL NAT WITH A SPECIFIC DATE (E.G., THE FIRST AVAILABLE DATE)\n",
    "# df['Date'].fillna(pd.Timestamp('2020-01-01'), inplace=True)\n",
    "\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong Data : Data of wrong data types can make it difficult, or even impossible, to analyze data.\n",
    "\n",
    "# df = pd.read_csv(\"Data_Cleaning.csv\")\n",
    "# df.types : To check the data type of each column\n",
    "# print(df.dtypes)\n",
    "\n",
    "# ==================================================================================================\n",
    "# Replacing Values\n",
    "# syntax : df.replace(value, new_value)\n",
    "# syntax : df.loc[row, column] = new_value\n",
    "# loc : Access a group of rows and columns by labels or a boolean array.\n",
    "# df.loc[7, \"Duration\"] = 45\n",
    "\n",
    "# ==================================================================================================\n",
    "# Replacing using loop\n",
    "# for x in df.index:\n",
    "#     if df.loc[x, \"Duration\"] > 120:\n",
    "#         df.loc[x, \"Duration\"] = 120\n",
    "\n",
    "# ==================================================================================================\n",
    "# Removing Rows\n",
    "# drop : Remove rows by index\n",
    "# for x in df.index:\n",
    "#     if df.loc[x, \"Duration\"] > 120:\n",
    "#         df.drop(x, inplace=True)\n",
    "\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Duration          Date  Pulse  Maxpulse  Calories\n",
      "0        610  '2020/12/01'    110       130     409.1\n",
      "1         60  '2020/12/02'    117       145     479.0\n",
      "2         60  '2020/12/03'    103       135     340.0\n",
      "3         45  '2020/12/04'    109       175     282.4\n",
      "4         45  '2020/12/05'    117       148     406.0\n",
      "5         60  '2020/12/06'    102       127     300.0\n",
      "6         60  '2020/12/07'    110       136     374.0\n",
      "7        450  '2020/12/08'    104       134     253.3\n",
      "8         30  '2020/12/09'    109       133     195.1\n",
      "9         60  '2020/12/10'     98       124     269.0\n",
      "10        60  '2020/12/11'    103       147     329.3\n",
      "11        60  '2020/12/12'    100       120     250.7\n",
      "13        60  '2020/12/13'    106       128     345.3\n",
      "14        60  '2020/12/14'    104       132     379.3\n",
      "15        60  '2020/12/15'     98       123     275.0\n",
      "16        60  '2020/12/16'     98       120     215.2\n",
      "17        60  '2020/12/17'    100       120     300.0\n",
      "18        50  '2020/12/18'     90       112       NaN\n",
      "19        60  '2020/12/19'    103       123     323.0\n",
      "20        45  '2020/12/20'     97       125     243.0\n",
      "21        60  '2020/12/21'    108       131     364.2\n",
      "22        55           NaN    100       119     282.0\n",
      "23        60  '2020/12/23'    130       101     300.0\n",
      "24        45  '2020/12/24'    105       132     246.0\n",
      "25        60  '2020/12/25'    102       126     334.5\n",
      "26        60      20201226    100       120     250.0\n",
      "27        60  '2020/12/27'     92       118     241.0\n",
      "28        60  '2020/12/28'    103       132       NaN\n",
      "29        60  '2020/12/29'    100       132     280.0\n",
      "30        60  '2020/12/30'    102       129     380.3\n",
      "31        60  '2020/12/31'     92       115     243.0\n"
     ]
    }
   ],
   "source": [
    "# Discovering Duplicates : Duplicates can make your analysis incorrect, so it is important\n",
    "# Duplicate rows are rows that have been registered more than one time.\n",
    "df = pd.read_csv(\"Data_Cleaning.csv\")\n",
    "\n",
    "# Returns True for every row that is a duplicate, otherwise False:\n",
    "# print(df.duplicated())\n",
    "\n",
    "# Removing Duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Engineer-Roadmap-9EaXoWEH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
