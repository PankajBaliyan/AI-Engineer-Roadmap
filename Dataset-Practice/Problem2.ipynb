{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T10:18:41.216262Z",
     "start_time": "2024-11-10T10:18:41.207196Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Libraries imported successfully ✅\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully ✅\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age   Salary  Gender   Department\n",
      "0   25.0  50000.0    Male        Sales\n",
      "1   25.0  50000.0    Male        Sales\n",
      "2   25.0  50000.0    Male        Sales\n",
      "3    NaN  52000.0     NaN  Engineering\n",
      "4   40.0      NaN  Female        Sales\n",
      "5  120.0  58000.0    Male    Marketing\n",
      "\n",
      "DataFrame after one-hot encoding:\n",
      "     Age   Salary  Gender_Male  Department_Marketing  Department_Sales\n",
      "0   25.0  50000.0         True                 False              True\n",
      "1   25.0  50000.0         True                 False              True\n",
      "2   25.0  50000.0         True                 False              True\n",
      "3    NaN  52000.0        False                 False             False\n",
      "4   40.0      NaN        False                 False              True\n",
      "5  120.0  58000.0         True                  True             False\n"
     ]
    }
   ],
   "source": [
    "# Create a sample DataFrame with 5 records and common data issues\n",
    "data = {\n",
    "    \"Age\": [\n",
    "        25,\n",
    "        25,\n",
    "        25,\n",
    "        np.nan,\n",
    "        40,\n",
    "        120,\n",
    "    ],  # Age has a missing value and an outlier (120)\n",
    "    \"Salary\": [50000, 50000, 50000, 52000, np.nan, 58000],  # Salary has a missing value\n",
    "    \"Gender\": [\n",
    "        \"Male\",\n",
    "        \"Male\",\n",
    "        \"Male\",\n",
    "        np.nan,\n",
    "        \"Female\",\n",
    "        \"Male\",\n",
    "    ],  # Gender has a missing value\n",
    "    \"Department\": [\n",
    "        \"Sales\",\n",
    "        \"Sales\",\n",
    "        \"Sales\",\n",
    "        \"Engineering\",\n",
    "        \"Sales\",\n",
    "        \"Marketing\",\n",
    "    ],  # Categorical variable\n",
    "}\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "# missing_values = df.isnull().sum()\n",
    "# print(f\"\\nMissing values in the DataFrame: \\n{missing_values}\")\n",
    "\n",
    "# .fillna() method to fill missing values\n",
    "# .median() method to calculate the median of a column, median is the middle value of a dataset\n",
    "# df[\"Age\"].fillna(df[\"Age\"].median(), inplace=True)\n",
    "\n",
    "# Fill missing categorical values in 'Gender' with the most frequent value (mode)\n",
    "# df[\"Gender\"].fillna(df[\"Gender\"].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "# check for duplicates in the DataFrame\n",
    "# duplicates = df.duplicated().sum()\n",
    "# print(f\"\\nDuplicate records in the DataFrame: {duplicates}\")\n",
    "\n",
    "# Check for outliers in the Age column\n",
    "# Outliers are values that are significantly higher or lower than the rest of the values in a dataset\n",
    "\n",
    "# Cap 'Age' values above 100 to 100\n",
    "# df[\"Age\"] = df[\"Age\"].apply(lambda x: 100 if x > 100 else x)\n",
    "\n",
    "# Display the DataFrame after handling outliers\n",
    "# print(\"\\nDataFrame after capping outliers in Age:\")\n",
    "# print(df)\n",
    "\n",
    "# Perform one-hot encoding on 'Gender' and 'Department' columns\n",
    "df_encoded = pd.get_dummies(df, columns=[\"Gender\", \"Department\"], drop_first=True)\n",
    "\n",
    "# Display the DataFrame after encoding\n",
    "print(\"\\nDataFrame after one-hot encoding:\")\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imported successfully ✅\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290.0</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340.0</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363.0</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>430.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target   Height   Width\n",
       "0   242.0  11.5200  4.0200\n",
       "1   290.0  12.4800  4.3056\n",
       "2   340.0  12.3778  4.6961\n",
       "3   363.0  12.7300  4.4555\n",
       "4   430.0  12.4440  5.1340"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "fish_data = pd.read_csv(\"../0.Databases/Fish-Market-dataset/Fish.csv\")\n",
    "\n",
    "fish_data = fish_data.drop(\n",
    "    columns=[\"Species\", \"Length1\", \"Length2\", \"Length3\"]\n",
    ")  # delete the column \"Species\", \"Length1\", \"Length2\", \"Length3\"\n",
    "fish_data = fish_data.head(5) # get the first 5 rows\n",
    "fish_data = fish_data.rename(columns={\"Weight\": \"Target\"}) # rename the column \"Weight\" to \"Target\"\n",
    "# fish_data = fish_data.reset_index(drop=True) # reset the index\n",
    "\n",
    "print(\"Dataset imported successfully ✅\")\n",
    "fish_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the dataset:\n",
      "Target    0\n",
      "Height    0\n",
      "Width     0\n",
      "dtype: int64\n",
      "Number of duplicates in the dataset:\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290.0</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340.0</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363.0</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>430.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target   Height   Width\n",
       "0   242.0  11.5200  4.0200\n",
       "1   290.0  12.4800  4.3056\n",
       "2   340.0  12.3778  4.6961\n",
       "3   363.0  12.7300  4.4555\n",
       "4   430.0  12.4440  5.1340"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing the data\n",
    "# 1. Check for missing values\n",
    "missing_values = fish_data.isnull().sum()\n",
    "print(\"Missing values in the dataset:\")\n",
    "print(missing_values)\n",
    "\n",
    "# 2. Check for duplicates\n",
    "duplicates = fish_data.duplicated().sum()\n",
    "print(\"Number of duplicates in the dataset:\")\n",
    "print(duplicates)\n",
    "\n",
    "# 3. Check for outliers\n",
    "# outliers = fish_data.describe()\n",
    "# print(\"Outliers in the dataset:\")\n",
    "# print(outliers)\n",
    "\n",
    "# 4. Check for data types\n",
    "# data_types = fish_data.dtypes\n",
    "# print(\"Data types in the dataset:\")\n",
    "# print(data_types)\n",
    "\n",
    "# 5. Check for unique values\n",
    "# unique_values = fish_data.nunique()\n",
    "# print(\"Unique values in the dataset:\")\n",
    "# print(unique_values)\n",
    "\n",
    "# 6. Check for the shape of the dataset\n",
    "# shape = fish_data.shape\n",
    "# print(\"Shape of the dataset:\")\n",
    "# print(shape)\n",
    "\n",
    "# 7. Check for the correlation between the features\n",
    "# correlation = fish_data.corr()\n",
    "# print(\"Correlation between the features:\")\n",
    "# print(correlation)\n",
    "\n",
    "# 8. Check for the distribution of the target variable\n",
    "# target_distribution = fish_data[\"Target\"].value_counts()\n",
    "# print(\"Distribution of the target variable:\")\n",
    "# print(target_distribution)\n",
    "\n",
    "# 9. Check for the distribution of the features\n",
    "# features_distribution = fish_data.drop(columns=[\"Target\"]).hist()\n",
    "# print(\"Distribution of the features:\")\n",
    "# print(features_distribution)\n",
    "\n",
    "# 10. Check for the skewness of the features\n",
    "# skewness = fish_data.drop(columns=[\"Target\"]).skew()\n",
    "# print(\"Skewness of the features:\")\n",
    "# print(skewness)\n",
    "\n",
    "fish_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Height   Width\n",
      "0  11.5200  4.0200\n",
      "1  12.4800  4.3056\n",
      "2  12.3778  4.6961\n",
      "3  12.7300  4.4555\n",
      "4  12.4440  5.1340\n",
      "0    242.0\n",
      "1    290.0\n",
      "2    340.0\n",
      "3    363.0\n",
      "4    430.0\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "# 1. Split the data into features and target variable\n",
    "X = fish_data.drop(columns=[\"Target\"]) # features\n",
    "y = fish_data[\"Target\"] # target variable\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "# 2. Select the features with the highest correlation with the target variable\n",
    "# correlation = fish_data.corr()\n",
    "# correlation_target = correlation[\"Target\"].abs().sort_values(ascending=False)\n",
    "# print(\"Features with the highest correlation with the target variable:\")\n",
    "# print(correlation_target)\n",
    "\n",
    "# 3. Select the features with the highest correlation with each other\n",
    "# correlation_features = fish_data.drop(columns=[\"Target\"]).corr()\n",
    "# correlation_features = correlation_features.abs().unstack().sort_values(ascending=False)\n",
    "# correlation_features = correlation_features[correlation_features < 1]\n",
    "# print(\"Features with the highest correlation with each other:\")\n",
    "# print(correlation_features)\n",
    "\n",
    "# 4. Select the features with the highest variance\n",
    "# variance = fish_data.var().sort_values(ascending=False)\n",
    "# print(\"Features with the highest variance:\")\n",
    "# print(variance)\n",
    "\n",
    "# 5. Select the features with the highest mutual information with the target variable\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# mutual_info = mutual_info_regression(X, y)\n",
    "# mutual_info = pd.Series(mutual_info, index=X.columns)\n",
    "# mutual_info = mutual_info.sort_values(ascending=False)\n",
    "# print(\"Features with the highest mutual information with the target variable:\")\n",
    "# print(mutual_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• random_state=42: This is an arbitrary seed value that ensures reproducibility. When you use the same random_state value (e.g., 42), you’ll get the same data split every time you run the code. Setting it to any integer value “locks” the split, making results reproducible.\n",
    "\n",
    "• How to see fixed data: To keep the split fixed, use any integer for random_state, like 42 or 0. Each time you run the code with the same random_state, X_train, X_test, y_train, and y_test will contain the same data.\n",
    "\n",
    "• How to get variable data every time: If you want a different split each time, set random_state=None or omit the random_state parameter entirely. This allows train_test_split to randomly split the data differently with each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Height   Width\n",
      "4  12.4440  5.1340\n",
      "2  12.3778  4.6961\n",
      "0  11.5200  4.0200\n",
      "3  12.7300  4.4555\n",
      "   Height   Width\n",
      "1   12.48  4.3056\n",
      "4    430.0\n",
      "2    340.0\n",
      "0    242.0\n",
      "3    363.0\n",
      "Name: Target, dtype: float64\n",
      "1    290.0\n",
      "Name: Target, dtype: float64\n",
      "Data split successfully ✅\n"
     ]
    }
   ],
   "source": [
    "# Split the Data:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# x_train: training data\n",
    "# x_test: testing data\n",
    "# y_train: training target\n",
    "# y_test: testing target\n",
    "# x: features\n",
    "# y: target variable\n",
    "# test_size: the percentage of the data that should be used for testing, 0.2 means 20% of the data will be used for testing\n",
    "# random_state: a seed value for the random number generator, this ensures that the data is split the same way every time the code is run, this is useful for reproducibility, 42 is a common seed value\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "\n",
    "print(\"Data split successfully ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a Model\n",
    "\n",
    "# 1. Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "\n",
    "# 2. Decision Tree Regression\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# model = DecisionTreeRegressor()\n",
    "\n",
    "# 3. Random Forest Regression\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# model = RandomForestRegressor()\n",
    "\n",
    "# 4. Support Vector Regression\n",
    "# from sklearn.svm import SVR\n",
    "# model = SVR()\n",
    "\n",
    "# 5. K-Nearest Neighbors Regression\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# model = KNeighborsRegressor()\n",
    "\n",
    "# 6. Gradient Boosting Regression\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# model = GradientBoostingRegressor()\n",
    "\n",
    "# 7. XGBoost Regression\n",
    "# from xgboost import XGBRegressor\n",
    "# model = XGBRegressor()\n",
    "\n",
    "# 8. LightGBM Regression\n",
    "# from lightgbm import LGBMRegressor\n",
    "# model = LGBMRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully ✅\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Height   Width\n",
      "1   12.48  4.3056\n",
      "[323.4743985]\n",
      "Mean Squared Error: 1120.535355159415\n",
      "R2 Score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pankajkumar/.local/share/virtualenvs/AI-Engineer-Roadmap-9EaXoWEH/lib/python3.12/site-packages/sklearn/metrics/_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# mean_squared_error\n",
    "# mean_squared_error: a metric that measures the average squared difference between the actual and predicted values\n",
    "# \t•\tMSE: A lower value indicates better performance; 0 means perfect predictions.\n",
    "y_pred = model.predict(X_test)\n",
    "print(X_test)\n",
    "print(y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# r2_score\n",
    "# r2_score: a metric that measures the proportion of the variance in the dependent variable that is predictable from the independent variables\n",
    "# \t•\tR² Score: Ranges from 0 to 1 (or negative for very poor models); closer to 1 means the model explains more variance.\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-Tune the Model\n",
    "# 1. Grid Search\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# parameters = {\n",
    "#     \"n_estimators\": [100, 200, 300],\n",
    "#     \"max_depth\": [5, 10, 15],\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(model, parameters, cv=5)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Height   Width\n",
      "1   12.48  4.3056\n",
      "Predictions:\n",
      "[323.4743985]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "print(X_test)\n",
    "\n",
    "# copy x_test to clipboard\n",
    "# X_test.to_clipboard()\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully ✅\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31m\u001B[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001B[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001B[33mPress CTRL+C to quit\u001B[0m\n",
      "/Users/pankajkumar/.local/share/virtualenvs/AI-Engineer-Roadmap-9EaXoWEH/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "[2024-10-27 00:48:33,652] ERROR in app: Exception on /predict [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pankajkumar/.local/share/virtualenvs/AI-Engineer-Roadmap-9EaXoWEH/lib/python3.12/site-packages/flask/app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pankajkumar/.local/share/virtualenvs/AI-Engineer-Roadmap-9EaXoWEH/lib/python3.12/site-packages/flask/app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pankajkumar/.local/share/virtualenvs/AI-Engineer-Roadmap-9EaXoWEH/lib/python3.12/site-packages/flask/app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pankajkumar/.local/share/virtualenvs/AI-Engineer-Roadmap-9EaXoWEH/lib/python3.12/site-packages/flask/app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/4c/vdjg0l7x24b884_dnprm8xt40000gn/T/ipykernel_46966/3850100009.py\", line 34, in predict\n",
      "    prediction = model.predict(input_data)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pankajkumar/.local/share/virtualenvs/AI-Engineer-Roadmap-9EaXoWEH/lib/python3.12/site-packages/sklearn/linear_model/_base.py\", line 306, in predict\n",
      "    return self._decision_function(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pankajkumar/.local/share/virtualenvs/AI-Engineer-Roadmap-9EaXoWEH/lib/python3.12/site-packages/sklearn/linear_model/_base.py\", line 285, in _decision_function\n",
      "    X = self._validate_data(X, accept_sparse=[\"csr\", \"csc\", \"coo\"], reset=False)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pankajkumar/.local/share/virtualenvs/AI-Engineer-Roadmap-9EaXoWEH/lib/python3.12/site-packages/sklearn/base.py\", line 654, in _validate_data\n",
      "    self._check_n_features(X, reset=reset)\n",
      "  File \"/Users/pankajkumar/.local/share/virtualenvs/AI-Engineer-Roadmap-9EaXoWEH/lib/python3.12/site-packages/sklearn/base.py\", line 443, in _check_n_features\n",
      "    raise ValueError(\n",
      "ValueError: X has 4 features, but LinearRegression is expecting 2 features as input.\n",
      "127.0.0.1 - - [27/Oct/2024 00:48:33] \"\u001B[35m\u001B[1mPOST /predict HTTP/1.1\u001B[0m\" 500 -\n",
      "/Users/pankajkumar/.local/share/virtualenvs/AI-Engineer-Roadmap-9EaXoWEH/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [27/Oct/2024 00:49:27] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Deploy the Model\n",
    "\n",
    "# 1. Save the model to a file\n",
    "import joblib\n",
    "filename = \"linear_regression_model.pkl\"\n",
    "joblib.dump(model, filename)\n",
    "print(\"Model saved successfully ✅\")\n",
    "\n",
    "# Load the model from the file\n",
    "# loaded_model = joblib.load(filename)\n",
    "# print(\"Model loaded successfully ✅\")\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "# predictions_loaded_model = loaded_model.predict(X_test)\n",
    "# print(\"Predictions using the loaded model:\")\n",
    "# print(predictions_loaded_model)\n",
    "\n",
    "\n",
    "# 2. Create a simple Flask application for inference.\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load(\"linear_regression_model.pkl\")\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    input_data = np.array([data[\"features\"]])  # Expecting JSON with 'features' key\n",
    "    prediction = model.predict(input_data)\n",
    "    return jsonify({\"prediction\": prediction[0]})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Test the API by sending a POST request:\n",
    "# curl -X POST http://127.0.0.1:5000/predict -H \"Content-Type: application/json\" -d '{\"features\": [2200, 3, 2, 2005]}'\n",
    "\n",
    "# Step 1: Import the requests library\n",
    "import requests\n",
    "\n",
    "# Step 2: Define the URL\n",
    "url = \"http://127.0.0.1:5000\"\n",
    "\n",
    "# Step 3: Define the data to be sent\n",
    "data = {\"features\": [0.5, 0.6, 0.7]}\n",
    "\n",
    "# Step 4: Send a POST request\n",
    "response = requests.post(f\"{url}/predict\", json=data)\n",
    "\n",
    "# Step 5: Get the prediction from the response\n",
    "prediction = response.json()[\"prediction\"]\n",
    "print(f\"Prediction: {prediction}\")\n",
    "\n",
    "# 4. Deploy the Flask application to a cloud platform like Heroku or AWS.\n",
    "# 5. Create a front-end application to interact with the API.\n",
    "# 6. Monitor the performance of the deployed model and retrain as needed.\n",
    "# 7. Continuously improve the model based on feedback and new data.\n",
    "\n",
    "# Conclusion\n",
    "# In this project, we learned how to preprocess data, select features, train a machine learning model, evaluate its performance, and deploy it for inference. We used a simple linear regression model for demonstration purposes, but the same process can be applied to more complex models and datasets. By following best practices and using the right tools, we can build robust and scalable machine learning applications that deliver value to users and stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Download dataset using kagglehub\n",
    "# import kagglehub\n",
    "\n",
    "# vipullrathod_fish_market_path = kagglehub.dataset_download(\"vipullrathod/fish-market\")\n",
    "\n",
    "# print(\"Data source import complete.\")\n",
    "\n",
    "# Step 2: Load the Dataset\n",
    "# data = pd.read_csv(vipullrathod_fish_market_path + \"/fish.csv\")\n",
    "# data.head()\n",
    "\n",
    "# Export / downlaod dataset\n",
    "# data.to_csv(\"my_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Engineer-Roadmap-9EaXoWEH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
